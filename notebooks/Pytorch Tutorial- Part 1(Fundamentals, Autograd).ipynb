{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"vscode":{"languageId":"plaintext"},"id":"ikIWspnpT9n_","executionInfo":{"status":"ok","timestamp":1754284654635,"user_tz":-330,"elapsed":4033,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d2e5e1d-e091-4f5e-ef46-2af50d609156"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","source":["if(torch.cuda.is_available()):\n","    print(\"cuda is available\")\n","else:\n","    print(\"Cuda not avaialble\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TS9MqgTamPhh","executionInfo":{"status":"ok","timestamp":1754284655603,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"2a7455cf-ee25-4720-c1b3-5a4449aee42c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda is available\n"]}]},{"cell_type":"markdown","source":["TENSOR Generation"],"metadata":{"id":"nLLxkkoWmhcw"}},{"cell_type":"code","source":["#empty\n","x1=torch.empty(2,3) #allocates memory and existing values are shown\n","print(x1)\n","print(type(x1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELyd9i7Amffo","executionInfo":{"status":"ok","timestamp":1748743372956,"user_tz":-330,"elapsed":137,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"88ac43a5-201d-4958-8632-b9dec8568bfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["#change type\n","x2=torch.empty(2,3,dtype=torch.int)\n","print(x2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52-q-stOnK5J","executionInfo":{"status":"ok","timestamp":1748743373007,"user_tz":-330,"elapsed":33,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"33e37477-8f7b-4289-f915-781036840985"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[        1,         0, 689147792],\n","        [        0, 689148296,         0]], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["#using zeroes\n","torch.zeros(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbFsqPIinrrB","executionInfo":{"status":"ok","timestamp":1748743373041,"user_tz":-330,"elapsed":32,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"70fd442e-63df-4c72-ec84-ecbe5b5c2799"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#Using Rand\n","torch.rand(2,3) # fills data with random values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBiiKwh0n1zR","executionInfo":{"status":"ok","timestamp":1748743373277,"user_tz":-330,"elapsed":233,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"53e59e64-82a9-4b70-bd20-86eede2b1732"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0123, 0.3821, 0.2879],\n","        [0.1477, 0.9433, 0.7231]])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#Manual Seed\n","torch.manual_seed(100)  #Fixes the random values\n","torch.rand(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlygVd8AoAKB","executionInfo":{"status":"ok","timestamp":1748743373310,"user_tz":-330,"elapsed":31,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"79368537-0be1-4743-9611-caddc15611da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1117, 0.8158, 0.2626],\n","        [0.4839, 0.6765, 0.7539]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["torch.manual_seed(100)  #Same random values are shown\n","torch.rand(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0hvQ5hKpo7a","executionInfo":{"status":"ok","timestamp":1748743373333,"user_tz":-330,"elapsed":21,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"282d322d-5bfc-451c-f0ff-79a3e94dc5a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1117, 0.8158, 0.2626],\n","        [0.4839, 0.6765, 0.7539]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Creating custom tensors\n","torch.tensor([[1,2,3],[4,5,6]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOp0uW6Hp-Gy","executionInfo":{"status":"ok","timestamp":1748743373548,"user_tz":-330,"elapsed":213,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"9f2455c3-e710-45fd-92f3-1cedd37dc81c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2, 3],\n","        [4, 5, 6]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#Arange\n","\n","print(\"Ordered scaler\",torch.arange(0,10))\n","\n","#linspace\n","\n","print(torch.linspace(-10,10,steps=5))\n","\n","#eye- returns a 2-D tensor with ones on the diagonal and zeros elsewhere, essentially creating an identity matrix\n","\n","print(torch.eye(5))\n","\n","#full- fills all the values with the given value in this case 4\n","\n","print(torch.full((2,3),4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3jCt0lLqQSy","executionInfo":{"status":"ok","timestamp":1748743373571,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"f42073aa-5206-41c4-8d3f-47053981ac06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ordered scaler tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","tensor([-10.,  -5.,   0.,   5.,  10.])\n","tensor([[1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.]])\n","tensor([[4, 4, 4],\n","        [4, 4, 4]])\n"]}]},{"cell_type":"markdown","source":["Tensor Shape"],"metadata":{"id":"5-R8YjN4rVdT"}},{"cell_type":"code","source":["print(x2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNvXiRJqqX3C","executionInfo":{"status":"ok","timestamp":1748743373602,"user_tz":-330,"elapsed":30,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"e9368e26-d472-4798-8327-004d47db63ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3])\n"]}]},{"cell_type":"code","source":["x3=torch.empty_like(x2)\n","print(x2) #values are integer\n","print(x3) #values are integer\n","print(x3.shape) #shape\n","print(x3.dtype) #data type"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0nN6s48rayb","executionInfo":{"status":"ok","timestamp":1748743373644,"user_tz":-330,"elapsed":38,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ee3136a4-b826-47e4-9dc4-396b21a527e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[        1,         0, 689147792],\n","        [        0, 689148296,         0]], dtype=torch.int32)\n","tensor([[ 572533794, 1701864804, 1852138606],\n","        [1936025955, 1952804191, 1948269090]], dtype=torch.int32)\n","torch.Size([2, 3])\n","torch.int32\n"]}]},{"cell_type":"code","source":["#playing with dtype\n","temp=torch.tensor([1.0,2.2,3.3],dtype=torch.int32)\n","print(temp)\n","\n","temp=torch.tensor([1.0,2.2,3.3],dtype=torch.float)\n","print(temp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5aRalV6r_20","executionInfo":{"status":"ok","timestamp":1748743373646,"user_tz":-330,"elapsed":15,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"60d3b1ca-b666-495d-a612-d08e07201d8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3], dtype=torch.int32)\n","tensor([1.0000, 2.2000, 3.3000])\n"]}]},{"cell_type":"markdown","source":["| **Data Type**             | **Dtype**         | **Description**                                                                                                                                                                |\n","|---------------------------|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n","| **32-bit Floating Point** | `torch.float32`   | Standard floating-point type used for most deep learning tasks. Provides a balance between precision and memory usage.                                                         |\n","| **64-bit Floating Point** | `torch.float64`   | Double-precision floating point. Useful for high-precision numerical tasks but uses more memory.                                                                               |\n","| **16-bit Floating Point** | `torch.float16`   | Half-precision floating point. Commonly used in mixed-precision training to reduce memory and computational overhead on modern GPUs.                                            |\n","| **BFloat16**              | `torch.bfloat16`  | Brain floating-point format with reduced precision compared to `float16`. Used in mixed-precision training, especially on TPUs.                                                |\n","| **8-bit Floating Point**  | `torch.float8`    | Ultra-low-precision floating point. Used for experimental applications and extreme memory-constrained environments (less common).                                               |\n","| **8-bit Integer**         | `torch.int8`      | 8-bit signed integer. Used for quantized models to save memory and computation in inference.                                                                                   |\n","| **16-bit Integer**        | `torch.int16`     | 16-bit signed integer. Useful for special numerical tasks requiring intermediate precision.                                                                                    |\n","| **32-bit Integer**        | `torch.int32`     | Standard signed integer type. Commonly used for indexing and general-purpose numerical tasks.                                                                                  |\n","| **64-bit Integer**        | `torch.int64`     | Long integer type. Often used for large indexing arrays or for tasks involving large numbers.                                                                                  |\n","| **8-bit Unsigned Integer**| `torch.uint8`     | 8-bit unsigned integer. Commonly used for image data (e.g., pixel values between 0 and 255).                                                                                    |\n","| **Boolean**               | `torch.bool`      | Boolean type, stores `True` or `False` values. Often used for masks in logical operations.                                                                                      |\n","| **Complex 64**            | `torch.complex64` | Complex number type with 32-bit real and 32-bit imaginary parts. Used for scientific and signal processing tasks.                                                               |\n","| **Complex 128**           | `torch.complex128`| Complex number type with 64-bit real and 64-bit imaginary parts. Offers higher precision but uses more memory.                                                                 |\n","| **Quantized Integer**     | `torch.qint8`     | Quantized signed 8-bit integer. Used in quantized models for efficient inference.                                                                                              |\n","| **Quantized Unsigned Integer** | `torch.quint8` | Quantized unsigned 8-bit integer. Often used for quantized tensors in image-related tasks.                                                                                     |\n"],"metadata":{"id":"5z4j1DURtLqk"}},{"cell_type":"markdown","source":["Mathematical Operations"],"metadata":{"id":"R-G__gRktQ4s"}},{"cell_type":"markdown","source":["1. Scaler Operations"],"metadata":{"id":"Xzyv6z71tTmF"}},{"cell_type":"code","source":["x = torch.rand(2,2)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmoNbWMztGEt","executionInfo":{"status":"ok","timestamp":1748743373688,"user_tz":-330,"elapsed":46,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"327489f0-967b-4e88-bd36-a0c5c0ffc9ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.2627, 0.0428],\n","        [0.2080, 0.1180]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# addition\n","x=x + 2\n","print(x)\n","# substraction\n","x=x - 2\n","print(x)\n","# multiplication\n","x=x * 3\n","print(x)\n","# division\n","x=x / 3\n","print(x)\n","# int division\n","x=(x * 100)//3\n","print(x)\n","# mod\n","x=((x * 100)//3)%2\n","print(x)\n","# power\n","x=x**2\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5Gjb49-tXrk","executionInfo":{"status":"ok","timestamp":1748743373690,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"96c7988e-afe1-4476-8416-6bce7139a41d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2.2627, 2.0428],\n","        [2.2080, 2.1180]])\n","tensor([[0.2627, 0.0428],\n","        [0.2080, 0.1180]])\n","tensor([[0.7881, 0.1285],\n","        [0.6241, 0.3541]])\n","tensor([[0.2627, 0.0428],\n","        [0.2080, 0.1180]])\n","tensor([[8., 1.],\n","        [6., 3.]])\n","tensor([[0., 1.],\n","        [0., 0.]])\n","tensor([[0., 1.],\n","        [0., 0.]])\n"]}]},{"cell_type":"markdown","source":["2. Element Wise Operation"],"metadata":{"id":"Vvx_-AA6txYE"}},{"cell_type":"code","source":["a = torch.rand(2,3)\n","b = torch.rand(2,3)\n","\n","print(a)\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OS7fdyXtuxt","executionInfo":{"status":"ok","timestamp":1748743373745,"user_tz":-330,"elapsed":54,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"593fd368-7f43-4460-a1cc-631faca9907f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1217, 0.7356, 0.7118],\n","        [0.7876, 0.4183, 0.9014]])\n","tensor([[0.9969, 0.7565, 0.2239],\n","        [0.3023, 0.1784, 0.8238]])\n"]}]},{"cell_type":"code","source":["# add\n","c=a + b\n","# sub\n","c=a - b\n","# multiply\n","c=a * b\n","# division\n","c=a / b\n","# power\n","c=a ** b\n","# mod\n","c=a % b"],"metadata":{"id":"dg8N2IwEt2-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c = torch.tensor([1, -2, 3, -4])\n","# abs\n","torch.abs(c) #Absolute values or modulas\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xld98QHwt8e-","executionInfo":{"status":"ok","timestamp":1748743373789,"user_tz":-330,"elapsed":46,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ced42fcf-920b-465c-89de-dead065cc1cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# negative\n","torch.neg(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqoxrVNuuHeV","executionInfo":{"status":"ok","timestamp":1748743373790,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"c9c02b53-ffe1-46bc-d619-428757e755a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1,  2, -3,  4])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["d = torch.tensor([1.4, 2.3, 3.7, 4.4])\n","# round\n","torch.round(d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5ovW07kuJft","executionInfo":{"status":"ok","timestamp":1754286389632,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"976775b1-5f48-4be3-9e19-756e3071c2bf"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 4., 4.])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# ceil\n","torch.ceil(d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhV9Zzy6uR1F","executionInfo":{"status":"ok","timestamp":1748743373862,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"70b52b7e-fd29-45de-ad64-760104f63a9a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2., 3., 4., 5.])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# floor\n","torch.floor(d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ux7n2JC5uVF8","executionInfo":{"status":"ok","timestamp":1748743373882,"user_tz":-330,"elapsed":19,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"60c59bab-821b-4055-db86-c61529df4aad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3., 4.])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# clamp\n","torch.clamp(d, min=2, max=3)#all the data inputs are in the range of 2 to 6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QbveWqLuXMF","executionInfo":{"status":"ok","timestamp":1748743373915,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"8eb55435-85b9-4123-8db9-ba5f88ea46b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.0000, 2.3000, 3.0000, 3.0000])"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["3. Reduction operation"],"metadata":{"id":"KdorSmDgu4p1"}},{"cell_type":"code","source":["e= torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)\n","print(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Pd3wRT_uZcF","executionInfo":{"status":"ok","timestamp":1748743373924,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"42aea4e0-d9a4-43a3-b006-c4907d6f872e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4., 6., 0.],\n","        [1., 9., 9.]])\n"]}]},{"cell_type":"code","source":["# sum\n","s=torch.sum(e)\n","print(s)\n","# sum along columns\n","s=torch.sum(e, dim=0)\n","print(s)\n","# sum along rows\n","s=torch.sum(e, dim=1)\n","print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LULfwtLvJYG","executionInfo":{"status":"ok","timestamp":1748743373954,"user_tz":-330,"elapsed":28,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"62743320-d794-417d-f264-9709584540c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(29.)\n","tensor([ 5., 15.,  9.])\n","tensor([10., 19.])\n"]}]},{"cell_type":"code","source":["# mean\n","print(torch.mean(e))\n","# mean along col\n","print(torch.mean(e, dim=0))\n","# mean along rows\n","print(torch.mean(e, dim=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YL9svTimwHq2","executionInfo":{"status":"ok","timestamp":1748743373962,"user_tz":-330,"elapsed":6,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"53914199-1b37-4e33-d606-397070424ae3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4.8333)\n","tensor([2.5000, 7.5000, 4.5000])\n","tensor([3.3333, 6.3333])\n"]}]},{"cell_type":"code","source":["# median\n","torch.median(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDN0HBBjwZGe","executionInfo":{"status":"ok","timestamp":1748743373971,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"854bce88-a9bb-467e-a63d-8439a6fbd095"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# max and min\n","print(torch.max(e))\n","print(torch.min(e))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KB9fvxFKwcF-","executionInfo":{"status":"ok","timestamp":1748743374005,"user_tz":-330,"elapsed":35,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"f705b57c-5836-4a95-aef9-161b0d595d28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(9.)\n","tensor(0.)\n"]}]},{"cell_type":"code","source":["# product\n","print(e)\n","print(torch.prod(e)) #as we have 0 the product is zeros."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86zCVFPyweiW","executionInfo":{"status":"ok","timestamp":1748743374020,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"3734615e-a6f0-47a7-f3cb-f7cd84ec398b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[4., 6., 0.],\n","        [1., 9., 9.]])\n","tensor(0.)\n"]}]},{"cell_type":"code","source":["# standard deviation\n","torch.std(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAPoTRWJyQp_","executionInfo":{"status":"ok","timestamp":1748743374023,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"c6b9f897-184b-4d3a-daaa-c3cff6acde21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.8687)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# variance\n","torch.var(e)"],"metadata":{"id":"GfqxruQ98Bgd","executionInfo":{"status":"ok","timestamp":1748743374035,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"0706c42d-a101-4c56-ba69-532e8e05d431","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(14.9667)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# argmax\n","torch.argmax(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mU7TP-BgJdBs","executionInfo":{"status":"ok","timestamp":1748743374074,"user_tz":-330,"elapsed":37,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"00686fb2-bde3-4530-e9c0-7d89afe43aab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# argmin\n","torch.argmin(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tk-yrtnfJlY0","executionInfo":{"status":"ok","timestamp":1748743374104,"user_tz":-330,"elapsed":28,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"e6cb4c87-3e74-4cb0-b0ab-089838289788"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["f = torch.randint(size=(2,3), low=0, high=10)\n","g = torch.randint(size=(3,2), low=0, high=10)\n","\n","print(f)\n","print(g)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lvsxa3rvJnpU","executionInfo":{"status":"ok","timestamp":1748743374104,"user_tz":-330,"elapsed":23,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"3d08263e-c228-48e8-9c14-6b750008f825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[8, 0, 7],\n","        [0, 0, 9]])\n","tensor([[5, 7],\n","        [3, 9],\n","        [4, 0]])\n"]}]},{"cell_type":"code","source":["torch.matmul(f, g)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaUZjcCWJrP0","executionInfo":{"status":"ok","timestamp":1748743374105,"user_tz":-330,"elapsed":15,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"1caa8af7-8733-4f19-d8bf-9ff5dfe71486"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[68, 56],\n","        [36,  0]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["vector1 = torch.tensor([1, 2])\n","vector2 = torch.tensor([3, 4])\n","\n","# dot product\n","torch.dot(vector1, vector2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDpQOua6Jtf7","executionInfo":{"status":"ok","timestamp":1748743374113,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"816f32ed-4bb5-4cac-de48-dfbd63fa4b77"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(11)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# transpose. 0 is rows and 1 is columns.\n","torch.transpose(f, 0, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adtuYfquJvzE","executionInfo":{"status":"ok","timestamp":1748743374125,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"decc7320-b33d-45a4-c9d8-3c9773a02b5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[8, 0],\n","        [0, 0],\n","        [7, 9]])"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["h = torch.randint(size=(3,3), low=0, high=10, dtype=torch.float32)\n","h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PmX01m3EKhNs","executionInfo":{"status":"ok","timestamp":1748743374157,"user_tz":-330,"elapsed":31,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"94db4d01-0d03-41dc-f5a6-3d4778e0e0f6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5., 7., 5.],\n","        [9., 9., 7.],\n","        [5., 9., 8.]])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# determinant\n","torch.det(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGIh7i6SKjzM","executionInfo":{"status":"ok","timestamp":1748743374166,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"57f63eb4-ba41-4ebb-fe35-c1edf1e09219"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-34.0000)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# inverse\n","torch.inverse(h)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l49eQqGSKlyc","executionInfo":{"status":"ok","timestamp":1748743374184,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"a5719c58-1add-4339-c927-b32168189561"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.2647,  0.3235, -0.1176],\n","        [ 1.0882, -0.4412, -0.2941],\n","        [-1.0588,  0.2941,  0.5294]])"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["i = torch.randint(size=(2,3), low=0, high=10)\n","j = torch.randint(size=(2,3), low=0, high=10)\n","\n","print(i)\n","print(j)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwPfcR0sKoHk","executionInfo":{"status":"ok","timestamp":1748743374228,"user_tz":-330,"elapsed":50,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"dd5317f0-ef4b-49cf-ec07-f9e3246475e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9, 7, 9],\n","        [2, 6, 7]])\n","tensor([[7, 8, 3],\n","        [6, 1, 5]])\n"]}]},{"cell_type":"code","source":["# greater than\n","i > j\n","# less than\n","i < j\n","# equal to\n","i == j\n","# not equal to\n","i != j\n","# greater than equal to\n","\n","# less than equal to"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fC34DTFhKseE","executionInfo":{"status":"ok","timestamp":1748743374248,"user_tz":-330,"elapsed":55,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"83dff67e-fee0-46de-d77d-dc6e8da560d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True, True],\n","        [True, True, True]])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["k = torch.randint(size=(2,3), low=0, high=10, dtype=torch.float32)\n","k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnnoK0PDK0YE","executionInfo":{"status":"ok","timestamp":1748743374249,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"6bbf8532-ffd5-4d8c-ae1e-48658794119b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5., 0., 4.],\n","        [3., 8., 8.]])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# log\n","torch.log(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lr2tYZPGK2wU","executionInfo":{"status":"ok","timestamp":1748743374256,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"a9e3276a-64cb-4d70-9d4a-a44cd01a7ac9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.6094,   -inf, 1.3863],\n","        [1.0986, 2.0794, 2.0794]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# exp\n","torch.exp(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyPxmVMaLAYE","executionInfo":{"status":"ok","timestamp":1748743374267,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"15827ba7-9034-4eef-8fcc-8d94a35f1182"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.4841e+02, 1.0000e+00, 5.4598e+01],\n","        [2.0086e+01, 2.9810e+03, 2.9810e+03]])"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# sqrt\n","torch.sqrt(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJsWyfZzLCtE","executionInfo":{"status":"ok","timestamp":1748743374277,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"b63d981f-38d8-4315-c5ec-631d83f4ebf0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.2361, 0.0000, 2.0000],\n","        [1.7321, 2.8284, 2.8284]])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# sigmoid\n","c=torch.sigmoid(k)"],"metadata":{"id":"a00deE9KLEKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Create a range of values from -10 to 10\n","x = c\n","\n","# Step 2: Apply sigmoid\n","y = torch.sigmoid(x)\n","\n","print(y)"],"metadata":{"id":"yBtA6om_LUYU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748743374313,"user_tz":-330,"elapsed":31,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"0f85b24c-450a-496f-b969-961808981a11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.7297, 0.6225, 0.7275],\n","        [0.7216, 0.7310, 0.7310]])\n"]}]},{"cell_type":"code","source":["# softmax\n","#Magic methods (also called dunder methods, short for \"double underscore\") are special functions that\n","#start and end with double underscores, like __init__, __str__, __add__, __len__, etc.\n","#Here the __float__ and __format__ are automatically called that converts\n","\n","#print x using formatting, like f\"{x:.1f}\",\n","#it automatically converts x into a normal float (like 3.14) behind the scenes\n","\n","c=torch.softmax(k, dim=0)\n","temp=[[f\"{x:.1f}\" for x in row] for row in c]\n","print(temp)\n","print(c)\n","#The dim parameter determines which axis of the tensor the softmax function operates on. Softmax transforms input values into a probability distribution, where each element is between 0 and 1, and the sum of elements along the specified dimension equals 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zz763Cg310WW","executionInfo":{"status":"ok","timestamp":1748743374351,"user_tz":-330,"elapsed":36,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"f6cc8a91-2035-49fc-ca1a-2fe532c32b03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['0.9', '0.0', '0.0'], ['0.1', '1.0', '1.0']]\n","tensor([[8.8080e-01, 3.3535e-04, 1.7986e-02],\n","        [1.1920e-01, 9.9966e-01, 9.8201e-01]])\n"]}]},{"cell_type":"code","source":["# relu\n","torch.relu(k)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xYTSfmHDzv7","executionInfo":{"status":"ok","timestamp":1748743374353,"user_tz":-330,"elapsed":29,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"e71ec5e2-bd82-4849-d278-8126ffb50638"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5., 0., 4.],\n","        [3., 8., 8.]])"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["Inplace Operation.\n","In PyTorch, an in-place operation modifies the contents of a tensor directly, without making a copy.\n","\n","You can usually recognize in-place operations by a trailing underscore _ in the function name."],"metadata":{"id":"WQTjLg68D4fM"}},{"cell_type":"code","source":["m = torch.rand(2,3)\n","n = torch.rand(2,3)\n","\n","print(m)\n","print(n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asDgdiw5D2P7","executionInfo":{"status":"ok","timestamp":1748743374387,"user_tz":-330,"elapsed":36,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"c21af583-01c9-4c80-e95a-209c750ed8f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6179, 0.3379, 0.2170],\n","        [0.9454, 0.7116, 0.1157]])\n","tensor([[0.6574, 0.3451, 0.0453],\n","        [0.9798, 0.5548, 0.6868]])\n"]}]},{"cell_type":"code","source":["m.add_(n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIetUv9KEHuL","executionInfo":{"status":"ok","timestamp":1748743374388,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"8bd46ea6-e130-4ce9-8a1b-9fc907e2f783"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.2752, 0.6830, 0.2624],\n","        [1.9251, 1.2663, 0.8025]])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["m.relu_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pf1chD2EJoc","executionInfo":{"status":"ok","timestamp":1748743374411,"user_tz":-330,"elapsed":33,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ca39bc7e-f31b-4bfa-ef53-acadc79181f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1.2752, 0.6830, 0.2624],\n","        [1.9251, 1.2663, 0.8025]])"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["Tensor Copying"],"metadata":{"id":"rjlQDRXREY0s"}},{"cell_type":"code","source":["a = torch.rand(2,3)\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eT3Ub0_EWxr","executionInfo":{"status":"ok","timestamp":1748743374411,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"7c5ebcff-e66a-4aa2-b27e-eb381542663e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4920, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["b = a\n","print(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87kqAYz5FCoD","executionInfo":{"status":"ok","timestamp":1748743374442,"user_tz":-330,"elapsed":33,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"3d38b74e-beec-4118-91a8-38deed56035c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4920, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])\n"]}]},{"cell_type":"code","source":["a[0][0] = 0"],"metadata":{"id":"7aWL1sK3FsNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Printing a:\",a)\n","print(\"Printing b:\",b)\n","#both have been affected.\n","#This does not create a copy — it simply makes a another name for the same tensor object in memory."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPm67Np_FtEd","executionInfo":{"status":"ok","timestamp":1748743374457,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ca0a5120-cc7e-48a0-868b-cb140402d828"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Printing a: tensor([[0.0000, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])\n","Printing b: tensor([[0.0000, 0.0748, 0.9605],\n","        [0.3271, 0.0103, 0.9516]])\n"]}]},{"cell_type":"code","source":["#The built-in Python function id(obj) returns the identity of the object — which is its memory address (or something unique to that object during its lifetime).\n","id(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L64TvQjQFFpL","executionInfo":{"status":"ok","timestamp":1748743374477,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"01020d7e-6923-4903-f22e-8d03576f9c35"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["133454538409360"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["id(b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGErCIuWFTST","executionInfo":{"status":"ok","timestamp":1748743374505,"user_tz":-330,"elapsed":34,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"5d081694-0313-45aa-936f-d66a79693221"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["133454538409360"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["b = a.clone()\n","#a.clone() creates a copy of the tensor a with the same data,\n","#dtype, device, and requires_grad status, but at a different memory location."],"metadata":{"id":"PJppLB6wFWGj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4GczrrFFfXM","executionInfo":{"status":"ok","timestamp":1748743374520,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"1fdbae1f-c387-48a0-e11c-ed471dc304d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["133454538409360"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["id(b)\n","#Different Set of Address because we have created a clone of it."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BS6f7sarGX3L","executionInfo":{"status":"ok","timestamp":1748743374571,"user_tz":-330,"elapsed":42,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ef2066f1-12c8-4f8d-ff21-0314a8b321f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["133454538410032"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["AUTOGRADING"],"metadata":{"id":"5XKCp7L3K7pC"}},{"cell_type":"markdown","source":["A dynamic computation graph (also called define-by-run) is a way of building and executing the computation graph on the fly as operations are performed. PyTorch uses this model — unlike TensorFlow 1.x, which used a static graph model.\n","\n","Autograd is PyTorch’s automatic differentiation engine — it automatically computes gradients for tensor operations, which is essential for training neural networks using backpropagation."],"metadata":{"id":"H8YPiZboK-7K"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"FZOEvmMTGakz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.tensor(3.0, requires_grad=False)\n","#requires gradient is true, pytorch knows that we will calculate gradient of this one, and will track each changes."],"metadata":{"id":"2BUbPeNYR0Zh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = x**2 #y=x^2 is the function"],"metadata":{"id":"g08dF8-RR_cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_F3S1cMsSCei","executionInfo":{"status":"ok","timestamp":1748743374652,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"58d579c5-2a6c-4982-e6eb-0dedaba41d8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3., requires_grad=True)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["y\n","#PowBackward indicates that from the computation graph that during\n","#calculation of y power was performed, so during backpropagation power backward needs to be performed."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bWpMLjPSG_p","executionInfo":{"status":"ok","timestamp":1748743374680,"user_tz":-330,"elapsed":27,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"9d649971-7fe2-43fe-8f77-7a03a0ef30d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(9., grad_fn=<PowBackward0>)"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["y.backward()\n","# This is calculating dy/dx; which in this case will be 2x. So 2*3=6\n","x.grad  #To visualize the derivative you have run x.grad; because the change is with respect to x."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrFty0FHSKTZ","executionInfo":{"status":"ok","timestamp":1748743374756,"user_tz":-330,"elapsed":78,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"5ca36eab-5743-4a3d-f342-8dbc5dd0de37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.)"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","source":["Now let us take an example; y=x^2 and z=sin(y). We have to calculate dz/dx"],"metadata":{"id":"8sWgVMw5UPSp"}},{"cell_type":"code","source":["x = torch.tensor(4.0, requires_grad=True)\n","y = x**2\n","z = torch.sin(y)\n"],"metadata":{"id":"pgIPG4h3Tz5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtecL-dIOD1F","executionInfo":{"status":"ok","timestamp":1748743374811,"user_tz":-330,"elapsed":53,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"44e7409a-9929-4673-fcc4-497283dee2c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-7.6613)"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["Single Perceptron Analysis (Neural Net)"],"metadata":{"id":"YAjOfgHIORMs"}},{"cell_type":"code","source":["import torch\n","\n","# Inputs\n","x = torch.tensor(6.7)  # Input feature\n","y = torch.tensor(0.0)  # True label (binary)\n","\n","w = torch.tensor(1.0)  # Weight\n","b = torch.tensor(0.0)  # Bias"],"metadata":{"id":"0mnhZN9lOHyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binary Cross-Entropy Loss for scalar\n","def binary_cross_entropy_loss(prediction, target):\n","    epsilon = 1e-8  # To prevent log(0)\n","    prediction = torch.clamp(prediction, epsilon, 1 - epsilon)\n","    #min(max(prediction ,epsilon),1-epsilon)\n","    return -(target * torch.log(prediction) + (1 - target) * torch.log(1 - prediction))"],"metadata":{"id":"B-lw4-ADOc1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Forward pass\n","z = w * x + b  # Weighted sum (linear part)\n","y_pred = torch.sigmoid(z)  # Predicted probability\n","\n","# Compute binary cross-entropy loss\n","loss = binary_cross_entropy_loss(y_pred, y)"],"metadata":{"id":"IV3ZF40vPL8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7y1myV7ZbLV","executionInfo":{"status":"ok","timestamp":1748743374914,"user_tz":-330,"elapsed":20,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"91668567-f7e6-4e5a-e121-10683c9d9530"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.7012)"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# Derivatives:\n","# 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)\n","dloss_dy_pred = (y_pred - y)/(y_pred*(1-y_pred))\n","\n","# 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)\n","dy_pred_dz = y_pred * (1 - y_pred)\n","\n","# 3. dz/dw and dz/db: z with respect to w and b\n","dz_dw = x  # dz/dw = x\n","dz_db = 1  # dz/db = 1 (bias contributes directly to z)\n","\n","dL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\n","dL_db = dloss_dy_pred * dy_pred_dz * dz_db"],"metadata":{"id":"m_TQibAGaCul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Manual Gradient of loss w.r.t weight (dw): {dL_dw}\")\n","print(f\"Manual Gradient of loss w.r.t bias (db): {dL_db}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFALJKjwaIs9","executionInfo":{"status":"ok","timestamp":1748743374957,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"1ad2bbb9-e585-4b65-bd96-3ee9f69b3c0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Manual Gradient of loss w.r.t weight (dw): 6.691762447357178\n","Manual Gradient of loss w.r.t bias (db): 0.998770534992218\n"]}]},{"cell_type":"markdown","source":["Now utilizing Autograd to Compute the Gradient"],"metadata":{"id":"pBbFQWTBaMUG"}},{"cell_type":"code","source":["x = torch.tensor(6.7)\n","y = torch.tensor(0.0)"],"metadata":{"id":"NtYhyKtpaP3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w = torch.tensor(1.0, requires_grad=True)\n","b = torch.tensor(0.0, requires_grad=True)"],"metadata":{"id":"_joPmMPyaScX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z = w*x + b\n","z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cnc-X-QaVaN","executionInfo":{"status":"ok","timestamp":1748743375007,"user_tz":-330,"elapsed":26,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"ebe63c13-2e34-48f4-d0c0-2c4912dbf288"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.7000, grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["y_pred = torch.sigmoid(z)\n","y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AIqokbUahK9","executionInfo":{"status":"ok","timestamp":1748743375015,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"5cc6cc8e-b924-4438-a096-992b8670b6e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9988, grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["loss = binary_cross_entropy_loss(y_pred, y)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtjBcacbanCl","executionInfo":{"status":"ok","timestamp":1748743375041,"user_tz":-330,"elapsed":24,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"e882b3b7-cb5a-4dae-eb3f-2ccabbe85a6c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.7012, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["loss.backward()"],"metadata":{"id":"QfK9dznYapn9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Autograd Gradient of loss w.r.t weight (dw): {w.grad}\")\n","print(f\"Autograd Gradient of loss w.r.t bias (db): {b.grad}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2935oLNarht","executionInfo":{"status":"ok","timestamp":1748743375091,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"3b42a08e-cc44-4709-d96c-9f45e1f74a78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Autograd Gradient of loss w.r.t weight (dw): 6.6917619705200195\n","Autograd Gradient of loss w.r.t bias (db): 0.9987704753875732\n"]}]},{"cell_type":"markdown","source":["Applying Autograd on multiple variables or multi-feature"],"metadata":{"id":"8xsaE0-6a7K-"}},{"cell_type":"code","source":["x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)"],"metadata":{"id":"6eZe_9jqa451"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = (x**2).mean()\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJQkXYWeclWt","executionInfo":{"status":"ok","timestamp":1748743375157,"user_tz":-330,"elapsed":39,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"0c76568b-9306-4f7f-ec35-4ceeeb33d6f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.6667, grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["y.backward()\n","print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juk5QqqgcoRF","executionInfo":{"status":"ok","timestamp":1748743375166,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"d51a3915-fde7-45f2-c5cd-906be9a8cce8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.6667, 1.3333, 2.0000])\n"]}]},{"cell_type":"code","source":["# clearing grad\n","x = torch.tensor(2.0, requires_grad=True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cw5qut7hc4v9","executionInfo":{"status":"ok","timestamp":1748743375261,"user_tz":-330,"elapsed":93,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"87158113-3885-44d7-865e-b3260d4b4e42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2., requires_grad=True)"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["y = x ** 2\n","y.backward()"],"metadata":{"id":"eUIx6P6cc9X1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjMvu7bbdCQd","executionInfo":{"status":"ok","timestamp":1748743375267,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"e6463d68-62ab-490b-b2b8-b472ab4db2b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4.)\n"]}]},{"cell_type":"code","source":["x.grad.zero_()\n","#Gradient needs to be brought to Zero, as it is a additive process. So for each pass\n","#it needs to be brought to zero."],"metadata":{"id":"Lvy9VI1Wqpiz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748743375320,"user_tz":-330,"elapsed":41,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"8b8639de-5a05-4959-bac2-cbc6913f7911"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.)"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["#Disabling Gradient Tracking\n","# option 1 - requires_grad_(False)\n","# option 2 - detach()\n","# option 3 - torch.no_grad()"],"metadata":{"id":"g1s9Ty2sPUoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#x.requires_grad_(False)\n","x.requires_grad_(False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1XWat5u-PcrW","executionInfo":{"status":"ok","timestamp":1748745465250,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"7af3c3eb-d6db-4c6a-87e0-8acad00a2e40"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.)"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["y = x ** 2"],"metadata":{"id":"lpI6eP-dPfJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.backward()# This occupies a lot a memory for a big neural network."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"ILrgq0SmPhzm","executionInfo":{"status":"error","timestamp":1748743631691,"user_tz":-330,"elapsed":80,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"82fe0e8a-1c06-409c-a100-b4808d4098ef"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-94-ab75bb780f4c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}]},{"cell_type":"code","source":["#x.detach()\n","x = torch.tensor(2.0, requires_grad=True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCai96aTPj5-","executionInfo":{"status":"ok","timestamp":1748743799728,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"4e8ee188-e5bb-4aaf-d57a-ae0a4af83534"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2., requires_grad=True)"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["z = x.detach()\n","z #z is a separate tensor that copies x but disbles gradient tracking."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLXZ6p0rQMiO","executionInfo":{"status":"ok","timestamp":1748743827667,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"36fcd8c0-52c0-4d16-c8b5-fc4bb3f09833"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.)"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["y1 = z ** 2\n","y1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KbXws9YwQg03","executionInfo":{"status":"ok","timestamp":1748743892666,"user_tz":-330,"elapsed":20,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"5cc92fba-52f8-4dcc-f161-ea8d6cd93f81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["y1.backward()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"p04HRYQwQhYm","executionInfo":{"status":"error","timestamp":1748743895964,"user_tz":-330,"elapsed":38,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"6e8a61ee-8c2b-4456-dbbd-d59a48453024"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-78ed6cb36aaa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}]},{"cell_type":"code","source":["#torch.no_grad()\n","\n","x = torch.tensor(2.0, requires_grad=True)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDr4EsfkRCAW","executionInfo":{"status":"ok","timestamp":1748744050746,"user_tz":-330,"elapsed":50,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"57ada43c-8bc1-48d0-8568-d05cae43876a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2., requires_grad=True)"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["with torch.no_grad():\n","    y = x ** 2\n","\n","y\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLXRgg0eRGqe","executionInfo":{"status":"ok","timestamp":1748745437205,"user_tz":-330,"elapsed":47,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"adbed5d2-46ea-41af-b710-2603517369a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["y.backward()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"sCiPK8cMRIM2","executionInfo":{"status":"error","timestamp":1748745439778,"user_tz":-330,"elapsed":65,"user":{"displayName":"Ayan Panja","userId":"07386613023293252846"}},"outputId":"b0d72646-7344-4b28-a870-52913ac7375b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-103-ab75bb780f4c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}